{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Utl4aeLvSUjG"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gsp4w4qnSZm5"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zy8r7ONVScka"
      },
      "outputs": [],
      "source": [
        "! cp '/content/drive/MyDrive/kaggle/kaggle.json' ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5rBxXhCTpWj"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t--ouBajTsm3"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttW-Kj5iV1dh"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deO2-O9NWD0a"
      },
      "outputs": [],
      "source": [
        "! unzip /content/chest-xray-pneumonia.zip -d pneumonia_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Directory with our training PNEUMONIA pictures\n",
        "train_PNEUMONIA_dir = '/content/pneumonia_dataset/chest_xray/train/PNEUMONIA'\n",
        "\n",
        "# Directory with our training NORMAL pictures\n",
        "train_NORMAL_dir = '/content/pneumonia_dataset/chest_xray/train/NORMAL'\n",
        "\n",
        "train_PNEUMONIA_names = os.listdir(train_PNEUMONIA_dir)\n",
        "print(train_PNEUMONIA_names[:10])\n",
        "\n",
        "train_NORMAL_names = os.listdir(train_NORMAL_dir)\n",
        "print(train_NORMAL_names[:10])\n"
      ],
      "metadata": {
        "id": "M2IPm3CZ4ziB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('total training PNEUMONIA images:', len(os.listdir(train_PNEUMONIA_dir)))\n",
        "print('total training NORMAL images:', len(os.listdir(train_NORMAL_dir)))"
      ],
      "metadata": {
        "id": "UYKyIcYN5AHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "\n",
        "# Index for iterating over images\n",
        "pic_index = 0"
      ],
      "metadata": {
        "id": "Kzo76drn5AsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols * 4, nrows * 4)\n",
        "\n",
        "pic_index += 8\n",
        "next_PNEUMONIA_pix = [os.path.join(train_PNEUMONIA_dir, fname)\n",
        "                for fname in train_PNEUMONIA_names[pic_index-8:pic_index]]\n",
        "next_NORMAL_pix = [os.path.join(train_NORMAL_dir, fname)\n",
        "                for fname in train_NORMAL_names[pic_index-8:pic_index]]\n",
        "\n",
        "for i, img_path in enumerate(next_PNEUMONIA_pix+next_NORMAL_pix):\n",
        "  # Set up subplot; subplot indices start at 1\n",
        "  sp = plt.subplot(nrows, ncols, i + 1)\n",
        "  sp.axis('Off') # Don't show axes (or gridlines)\n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "D5dQf7Hf5CQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Set up the directories\n",
        "train_dir = '/content/pneumonia_dataset/chest_xray/train'\n",
        "test_dir = '/content/pneumonia_dataset/chest_xray/test'\n",
        "validation_dir = '/content/pneumonia_dataset/chest_xray/val'\n",
        "\n",
        "# Data preprocessing and augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(300, 300),\n",
        "    batch_size=20,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = train_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(300, 300),\n",
        "    batch_size=20,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(300, 300),\n",
        "    batch_size=20,\n",
        "    class_mode='binary'\n",
        ")\n"
      ],
      "metadata": {
        "id": "z65frpim3tUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Model architecture\n",
        "model = tf.keras.models.Sequential([\n",
        "    Conv2D(16, (3, 3), activation='relu', input_shape=(300, 300, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Use sigmoid for binary classification\n",
        "])"
      ],
      "metadata": {
        "id": "d_X0DvEv7Enz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Callback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if logs.get('accuracy') >= 0.94:\n",
        "            print(\"\\nReached 94% accuracy. Stopping training.\")\n",
        "            self.model.stop_training = True"
      ],
      "metadata": {
        "id": "OEvz0ydZ2-Or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = Callback()\n",
        "# Model compilation\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(learning_rate=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fryziJoG3wx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=15,\n",
        "    epochs=25,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=8,\n",
        "    callbacks=[callback]\n",
        ")"
      ],
      "metadata": {
        "id": "-tvj2pmb3zxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "    path = '/content/' + fn\n",
        "    img = load_img(path, target_size=(300, 300))\n",
        "    x = img_to_array(img)\n",
        "    x /= 255\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    images = np.vstack([x])\n",
        "    classes = model.predict(images, batch_size=32)\n",
        "\n",
        "    print(\"Prediction:\", classes[0])\n",
        "    print(\"Threshold:\", 0.5)\n",
        "\n",
        "    if classes[0] > 0.5:\n",
        "        print(fn + \" HAS PNEUMONIA\")\n",
        "    else:\n",
        "        print(fn + \" IS NORMAL\")\n"
      ],
      "metadata": {
        "id": "jkTFwb9g_37r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vPjVvAndAgQD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}